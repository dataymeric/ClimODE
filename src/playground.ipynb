{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "\n",
    "from icecream import ic, install\n",
    "\n",
    "install()\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_167660/3427963463.py:88: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  k: pd.date_range(*p, freq=str(config[\"freq\"]) + \"H\")\n",
      "INFO:root:Raw data loaded, merged and normalized\n",
      "INFO:root:Raw data disk size: 777.712696 MiB\n",
      "INFO:root:Velocities for train loaded from cache\n",
      "INFO:root:Velocities for val loaded from cache\n",
      "INFO:root:Velocities for test loaded from cache\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from model.models import ClimODE\n",
    "from model.velocity import get_kernel, get_velocities\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.loss import CustomGaussianNLLLoss\n",
    "\n",
    "import data.loading as loading\n",
    "from data.dataset import Forcasting_ERA5Dataset\n",
    "from data.embeddings import get_time_localisation_embeddings\n",
    "from data.processing import select_data\n",
    "\n",
    "variables_time_dependant = [\"t2m\", \"t\", \"z\", \"u10\", \"v10\"]\n",
    "variables_static = [\"lsm\", \"orography\"]\n",
    "\n",
    "gpu_device = torch.device(\"cpu\")  # fallback to cpu\n",
    "if torch.cuda.is_available():\n",
    "    gpu_device = torch.device(\"cuda\")\n",
    "    torch.cuda.empty_cache()\n",
    "elif torch.backends.mps.is_available():\n",
    "    gpu_device = torch.device(\"mps\")\n",
    "    torch.mps.empty_cache()\n",
    "\n",
    "config = {\n",
    "    \"data_path_wb1\": \"../data/era5_data/\",\n",
    "    \"data_path_wb2\": \"../data/1959-2023_01_10-6h-64x32_equiangular_conservative.zarr\",\n",
    "    \"freq\": 6,  # In hours\n",
    "    \"nb_variable_time_dependant\": len(variables_time_dependant),\n",
    "    \"periods\": {\n",
    "        \"train\": (\"2006-01-01\", \"2015-12-31\"),\n",
    "        \"val\": (\"2016-01-01\", \"2016-12-31\"),\n",
    "        \"test\": (\"2017-01-01\", \"2018-12-31\"),\n",
    "    },\n",
    "    \"vel\": {\n",
    "        \"rbf_alpha\": 1.0,\n",
    "        \"stacking\": 3,\n",
    "        \"bs\": 50,\n",
    "        \"fitting_epoch\": 200,\n",
    "        \"regul_coeff\": 1e-7,\n",
    "        \"lr\": 2,\n",
    "        \"device\": gpu_device,\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"VelocityModel\": {\n",
    "            \"local\": {\n",
    "                \"in_channels\": 30 + 34,  # 34 d'embeding, 30 = jsp\n",
    "                \"layers_length\": [5, 3, 2],\n",
    "                \"layers_hidden_size\": [128, 64, 2 * 5],\n",
    "                # 5 = out_types = len(paths_to_data)\n",
    "            },\n",
    "            \"global\": {\n",
    "                \"in_channels\": 30 + 34,\n",
    "                \"out_channels\": 2 * 5,\n",
    "            },\n",
    "            \"gamma\": 0.1,\n",
    "        },\n",
    "        \"EmissionModel\": {\n",
    "            \"in_channels\": 9 + 34,  # err_in ; je sais pas pourquoi 9\n",
    "            \"layers_length\": [3, 2, 2],\n",
    "            \"layers_hidden_size\": [\n",
    "                128,\n",
    "                64,\n",
    "                2 * len(variables_time_dependant),\n",
    "            ],  # 5 = out_types = len(paths_to_data)\n",
    "        },\n",
    "        \"norm_type\": \"batch\",\n",
    "        \"n_res_blocks\": [3, 2, 2],\n",
    "        \"kernel_size\": 3,\n",
    "        \"stride\": 1,\n",
    "        \"dropout\": 0.1,\n",
    "    },\n",
    "    \"bs\": 8,\n",
    "    \"max_epoch\": 300,\n",
    "    \"lr\": 0.0005,\n",
    "    \"device\": gpu_device,\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # check the script is executed within the parent directory\n",
    "\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    periods = {\n",
    "        k: pd.date_range(*p, freq=str(config[\"freq\"]) + \"H\")\n",
    "        for (k, p) in config[\"periods\"].items()\n",
    "    }\n",
    "    raw_data = loading.wb1(config[\"data_path_wb1\"], periods)\n",
    "    train_raw_data = raw_data.sel(time=periods[\"train\"])\n",
    "    # data = loading.wb2(config[\"data_path_wb2\"], periods)\n",
    "\n",
    "    logging.info(\"Raw data loaded, merged and normalized\")\n",
    "    logging.info(\"Raw data disk size: {} MiB\".format(raw_data.nbytes / 1e6))\n",
    "\n",
    "    data_selected = select_data(raw_data, periods)\n",
    "\n",
    "    kernel = get_kernel(raw_data, config[\"vel\"])\n",
    "    data_velocities = get_velocities(data_selected, kernel, config)\n",
    "    train_velocities = torch.cat(tuple(data_velocities[\"train\"].values()), dim=1).view(\n",
    "        -1, 32, 64, 10\n",
    "    )  # (1826, 10, 32, 64) -> (1826, 32, 64, 10) pour compatibilité avec les futurs cat\n",
    "\n",
    "    train_data = torch.cat(\n",
    "        [t.unsqueeze(-1) for t in data_selected[\"train\"].values()], dim=-1\n",
    "    )\n",
    "    dataset = Forcasting_ERA5Dataset(train_data)\n",
    "    train_loader = DataLoader(dataset, batch_size=config[\"bs\"], shuffle=True)\n",
    "\n",
    "    time_step = torch.Tensor(list(range(len(train_data))))\n",
    "    time_step = torch.arange(0, len(train_data), 1)\n",
    "    # time_step = torch.Tensor(list(range(22)))\n",
    "    time_pos_embedding = get_time_localisation_embeddings(\n",
    "        time_step,\n",
    "        torch.tensor(train_raw_data[\"lat\"].values),\n",
    "        torch.tensor(train_raw_data[\"lon\"].values),\n",
    "        torch.tensor(train_raw_data[\"lsm\"].values),\n",
    "        torch.tensor(train_raw_data[\"orography\"].values),\n",
    "    ).float()  # float64 to float32 (important for conv) TODO\n",
    "    model = ClimODE(config, time_pos_embedding)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config[\"lr\"])\n",
    "    criterion = CustomGaussianNLLLoss()\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model.conv import ClimateResNet2D\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchdiffeq import odeint\n",
    "\n",
    "\"\"\"\n",
    "WIP\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class EmissionModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Equivalent of noise_net_contrib() using a class format.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, time_pos_embedding):\n",
    "        super().__init__()\n",
    "        self.sub_config = config[\"model\"][\"EmissionModel\"]\n",
    "        self.model = ClimateResNet2D(\n",
    "            self.sub_config[\"in_channels\"],\n",
    "            self.sub_config[\"layers_length\"],\n",
    "            self.sub_config[\"layers_hidden_size\"],\n",
    "            config,\n",
    "        )\n",
    "        self.time_pos_embedding = time_pos_embedding\n",
    "        self.nb_var_time_dep = config[\"nb_variable_time_dependant\"]\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        t,\n",
    "        x,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        WIP, not tested yet.\n",
    "        \"\"\"\n",
    "        ic(x.shape)  # [8, 32, 64, 5]\n",
    "        original_x = x.reshape(\n",
    "            8, self.nb_var_time_dep, 32, 64\n",
    "        )  # view fonctionne pas et puis anyway j'dois faire une copy\n",
    "        x = torch.cat([x, self.time_pos_embedding[t]], dim=-1)\n",
    "        x = x.view(\n",
    "            8, -1, 32, 64\n",
    "        )  # Matching conv shape (8, 32, 64, 43) -> (8, 43, 32, 64)\n",
    "        x = self.model(x)\n",
    "        ic(\n",
    "            x.shape, # [8, 10, 32, 64]\n",
    "            x[:, : self.nb_var_time_dep].shape, original_x.shape\n",
    "        )  \n",
    "        # From original code, not sure if it's correct\n",
    "        mean = original_x + x[:, : self.nb_var_time_dep]\n",
    "        std = F.softmax(x[:, self.nb_var_time_dep :])\n",
    "        return mean, std\n",
    "\n",
    "\n",
    "class AttentionModel(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        hidden_channels = in_channels // 2\n",
    "        self.query = self.make_layer(\n",
    "            in_channels, in_channels // 8, hidden_channels, stride=1, padding=True\n",
    "        )\n",
    "        self.key = self.make_layer(\n",
    "            in_channels, in_channels // 8, hidden_channels, stride=2\n",
    "        )\n",
    "        self.value = self.make_layer(\n",
    "            in_channels, out_channels, hidden_channels, stride=2\n",
    "        )\n",
    "        self.post_map = nn.Conv2d(out_channels, out_channels, kernel_size=(1, 1))\n",
    "\n",
    "    @staticmethod\n",
    "    def make_layer(in_channels, out_channels, hidden_channels, stride, padding=False):\n",
    "        def get_block(in_channels, out_channels, stride, padding):\n",
    "            if padding:\n",
    "                block = [\n",
    "                    nn.ReflectionPad2d((0, 0, 1, 1)),\n",
    "                    nn.CircularPad2d((1, 1, 0, 0)),\n",
    "                ]\n",
    "            else:\n",
    "                block = []\n",
    "\n",
    "            block += [\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), stride=stride),\n",
    "                nn.LeakyReLU(0.3),\n",
    "            ]\n",
    "            return block\n",
    "\n",
    "        return nn.Sequential(\n",
    "            *get_block(in_channels, hidden_channels, stride, padding),\n",
    "            *get_block(hidden_channels, out_channels, stride, padding),\n",
    "            *get_block(out_channels, out_channels, 1, padding),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"WIP\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : _type_\n",
    "            shape code origin: (1, 64, 32, 64)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        _type_\n",
    "            _description_\n",
    "        \"\"\"\n",
    "        # On flatten sur la latitude et la longitude\n",
    "        q = self.query(x).flatten(-2, -1)  # (1, 64, 32, 64) -> (1, 64, 2048)\n",
    "        k = self.key(x).flatten(-2, -1)  # (1, 8, 3, 13) -> (1, 8, 65)\n",
    "        v = self.value(x).flatten(-2, -1)  # (1, 10, 3, 13) -> (1, 10, 65)\n",
    "        # ic(q.shape, k.shape, v.shape)\n",
    "        # Il doit y avoir moyen de mieux faire, le contiguous est salle je pense\n",
    "        attention_beta = F.softmax(torch.bmm(q.transpose(1, 2), k), dim=1)\n",
    "        attention_beta = torch.bmm(v, attention_beta.transpose(1, 2))\n",
    "        attention_beta = attention_beta.view(1, -1, 32, 64).contiguous()\n",
    "        # ic(self.post_map(attention_beta).shape) # (1, 10, 32, 64)\n",
    "        return self.post_map(attention_beta)\n",
    "        \"\"\"\n",
    "        size = x.size()\n",
    "        x = x.float()\n",
    "        q, k, v = (\n",
    "            self.query(x).flatten(-2, -1),\n",
    "            self.key(x).flatten(-2, -1),\n",
    "            self.value(x).flatten(-2, -1),\n",
    "        )\n",
    "        beta = F.softmax(torch.bmm(q.transpose(1, 2), k), dim=1)\n",
    "        o = torch.bmm(v, beta.transpose(1, 2))\n",
    "        o = self.post_map(o.view(-1, self.out_ch, size[-2], size[-1]).contiguous())\n",
    "        return o\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "class VelocityModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Equivalent of $f_\\theta$ in the paper.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, time_pos_embedding):\n",
    "        super().__init__()\n",
    "        sub_config = config[\"model\"][\"VelocityModel\"]\n",
    "        self.time_pos_embedding = time_pos_embedding\n",
    "        self.local_model = ClimateResNet2D(\n",
    "            sub_config[\"local\"][\"in_channels\"],\n",
    "            sub_config[\"local\"][\"layers_length\"],\n",
    "            sub_config[\"local\"][\"layers_hidden_size\"],\n",
    "            config,\n",
    "        )\n",
    "        self.global_model = AttentionModel(\n",
    "            sub_config[\"global\"][\"in_channels\"],\n",
    "            sub_config[\"global\"][\"out_channels\"],\n",
    "        )  # input original code ([1, 64, 32, 64])\n",
    "        self.gamma = nn.Parameter(torch.tensor([sub_config[\"gamma\"]]))\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        \"\"\"\n",
    "        WIP, not tested yet.\n",
    "        Input must directly have all the parameters concatenated.\n",
    "        x: shape: (32,64,15) -> (32,64,10) + (32,64,5)\n",
    "        \"\"\"\n",
    "\n",
    "        # Obligé de cat avant puis uncat ici car odeint ne peut pas split ces param je pense\n",
    "        # pour le coup un tensors dict ici serait plus propre mais plus le temps\n",
    "        # Si on passe en (batch, timestep, année, ...,...), il faudra rajouter un :\n",
    "        past_velocity = x[:, :, :10]  # v in original code\n",
    "        past_velocity_x = past_velocity[:, :, :5]\n",
    "        past_velocity_y = past_velocity[:, :, 5:]\n",
    "        past_velocity_grad_x = torch.gradient(past_velocity_x, dim=-2)[0]\n",
    "        past_velocity_grad_y = torch.gradient(past_velocity_y, dim=-3)[0]\n",
    "\n",
    "        x_0 = x[:, :, 10:]  # ds in original code\n",
    "        x_0_grad_x = torch.gradient(x_0, dim=-2)[0]  # sur la dim de la logitude (64)\n",
    "        x_0_grad_y = torch.gradient(x_0, dim=-3)[0]  # sur la dim de la latitude (32)\n",
    "        nabla_u = torch.cat([x_0_grad_x, x_0_grad_y], dim=-1)  # (32,64,2*5)\n",
    "\n",
    "        t_emb = t.view(1, 1, 1).expand(32, 64, 1)\n",
    "        t = int(t.item()) * 100\n",
    "        # ic(\n",
    "        #     x.shape,\n",
    "        #     nabla_u.shape,\n",
    "        #     self.time_pos_embedding[t].shape,\n",
    "        #     past_velocity.shape,\n",
    "        #     x_0.shape,\n",
    "        # )\n",
    "\n",
    "        x = torch.cat([t_emb, x, nabla_u, self.time_pos_embedding[t]], dim=-1)\n",
    "        # Unsquueze for simulate a batch of 1\n",
    "        # and inverting the last dimension to the match CNN style conv (sorry j'aurai pu le faire avant j'ai merdé tant pis TODO)\n",
    "        x = x.view(1, 64, 32, 64)\n",
    "        dv = self.local_model(x)\n",
    "        dv += self.gamma * self.global_model(x)\n",
    "        dv = dv.squeeze().view(32, 64, -1)  # (32, 64, 10)\n",
    "\n",
    "        adv1 = past_velocity_x * x_0_grad_x + past_velocity_y * x_0_grad_y\n",
    "        adv2 = x_0 * (past_velocity_grad_x + past_velocity_grad_y)\n",
    "\n",
    "        # ic(dv.shape, adv1.shape, adv2.shape)\n",
    "        dvs = torch.cat([dv, adv1 + adv2], dim=-1)\n",
    "        return dvs\n",
    "\n",
    "\n",
    "class ClimODE(nn.Module):\n",
    "    def __init__(self, config, time_pos_embedding):\n",
    "        super(ClimODE, self).__init__()\n",
    "        self.config = config\n",
    "        self.device = config[\"device\"]\n",
    "        self.freq = config[\"freq\"]\n",
    "        self.velocity_model = VelocityModel(config, time_pos_embedding)\n",
    "        self.emission_model = EmissionModel(config, time_pos_embedding)\n",
    "        self.time_pos_embedding = time_pos_embedding\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        \"\"\"\n",
    "        WIP, not tested yet.\n",
    "        \"\"\"\n",
    "\n",
    "        # Calcul of news timesteps\n",
    "        init_time = t[0].item() * self.freq\n",
    "        final_time = t[-1].item() * self.freq\n",
    "        steps_val = final_time - init_time\n",
    "        ode_t = 0.01 * torch.linspace(\n",
    "            init_time, final_time, steps=int(steps_val) + 1\n",
    "        ).to(self.device)  # Je sais pas pourquoi 0.01\n",
    "\n",
    "        # Solvings ODE\n",
    "        x = odeint(self.velocity_model, x, ode_t, method=\"euler\")\n",
    "        # ic(x.shape) # torch.Size([43, 32, 64, 15])\n",
    "        x = x[\n",
    "            :, :, :, -5:\n",
    "        ]  # On récupère que les données de la prédiction uniquement, pas des past velocities si je comprends bien ???\n",
    "        # Nan je sais pas\n",
    "        # ic(x.shape) # torch.Size([43, 32, 64, 5])\n",
    "        x = x[::6]  # idk pourquoi on fait ça, je crois qu'on rediscretise en 8 morceaux\n",
    "        # ic(x.shape) # ([8, 32, 64, 5])\n",
    "        mean, std = self.emission_model(t, x)\n",
    "        return mean, std\n",
    "\n",
    "\n",
    "model = ClimODE(config, time_pos_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| x.shape: torch.Size([8, 32, 64, 5])\n",
      "ic| x.shape: torch.Size([8, 10, 32, 64])\n",
      "    x[:, : self.nb_var_time_dep].shape: torch.Size([8, 5, 32, 64])\n",
      "    original_x.shape: torch.Size([8, 5, 32, 64])\n",
      "/tmp/ipykernel_167660/860618382.py:52: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  std = F.softmax(x[:, self.nb_var_time_dep :])\n",
      "ic| x.shape: torch.Size([8, 32, 64, 5])\n",
      "ic| x.shape: torch.Size([8, 5, 32, 64])\n",
      "ic| y_forecast.shape: torch.Size([7, 32, 64, 5])\n",
      "ic| x.shape: torch.Size([8, 32, 64, 5])\n",
      "ic| x.shape: torch.Size([8, 10, 32, 64])\n",
      "    x[:, : self.nb_var_time_dep].shape: torch.Size([8, 5, 32, 64])\n",
      "    original_x.shape: torch.Size([8, 5, 32, 64])\n",
      "ic| x.shape: torch.Size([8, 32, 64, 5])\n",
      "ic| x.shape: torch.Size([8, 5, 32, 64])\n",
      "ic| y_forecast.shape: torch.Size([7, 32, 64, 5])\n",
      "ic| x.shape: torch.Size([8, 32, 64, 5])\n",
      "ic| x.shape: torch.Size([8, 10, 32, 64])\n",
      "    x[:, : self.nb_var_time_dep].shape: torch.Size([8, 5, 32, 64])\n",
      "    original_x.shape: torch.Size([8, 5, 32, 64])\n",
      "ic| x.shape: torch.Size([8, 32, 64, 5])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnb_variable_time_dependant\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m64\u001b[39m)\n\u001b[1;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(x, mean, std, var_coeff)\n\u001b[0;32m---> 22\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m ic(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     25\u001b[0m ic(y_forecast\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/tempory/climODE_combo/ClimODE/.venv/lib/python3.9/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tempory/climODE_combo/ClimODE/.venv/lib/python3.9/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(config[\"max_epoch\"]):\n",
    "    if epoch == 0:\n",
    "        var_coeff = 0.001\n",
    "    else:\n",
    "        var_coeff = 2 * scheduler.get_last_lr()[0]\n",
    "    for i, x in enumerate(train_loader):\n",
    "        t = time_step[i * config[\"bs\"] : (i + 1) * config[\"bs\"]]\n",
    "        y_forecast = x[1:].to(gpu_device)\n",
    "        # Past velocities cat with x[0]\n",
    "        x_0 = torch.cat((train_velocities[i], x[0]), dim=-1)\n",
    "        # simplement i car indexé comme ça, demander mathis why mais anyway,\n",
    "        # maybe parce que c'est long à compute donc on en fait le minimum\n",
    "        # train_velocities.shape: torch.Size([1826, 32, 64, 10])\n",
    "        # train_data.shape: torch.Size([14605, 32, 64, 5])\n",
    "        # 14605/8: 1825.625\n",
    "\n",
    "        mean, std = model(t, x_0)\n",
    "        # ic(mean.shape, std.shape) # [8, 5, 32, 64] both\n",
    "        ic(x.shape)\n",
    "        x = x.view(-1, config['nb_variable_time_dependant'], 32, 64)\n",
    "        loss = criterion(x, mean, std, var_coeff)\n",
    "        loss.backward()\n",
    "\n",
    "        ic(x.shape)\n",
    "        ic(y_forecast.shape)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = torch.tensor(raw_data.coords[\"lat\"].values)\n",
    "lon = torch.tensor(raw_data.coords[\"lon\"].values)\n",
    "lsm = torch.tensor(raw_data.lsm.values)\n",
    "oro = torch.tensor(raw_data.orography.values)\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "def print_time(t, paper=False):\n",
    "    day_in_years = t / 24  # 365 or 366\n",
    "    hours_of_day = t % 24\n",
    "    day_of_years = t // 24\n",
    "    (torch.sin(2 * torch.pi * hours_of_day),)  # sin temporal embedding\n",
    "    (torch.sin(2 * torch.pi * day_of_years / day_in_years),)  # sin seasonal embedding\n",
    "    print(f\"{t%24}ème heure\")\n",
    "    print(f\"{t//24}ème jour\")\n",
    "    print(f\"Sinus hour: {math.sin(t%24)}\")\n",
    "    print(f\"Sinus day: {math.sin(t//24)}\")\n",
    "    if paper:\n",
    "        t_papier = t % 24\n",
    "        print(\"\\npapier\")\n",
    "        print(f\"{t_papier}ème heure\")\n",
    "        print(f\"{t_papier/24}ème jour\")\n",
    "        print(f\"Sinus hour: {math.sin(t_papier%24 - math.pi / 2)}\")\n",
    "        print(f\"Sinus day: {math.sin(t_papier/24 - math.pi / 2)}\")\n",
    "\n",
    "\n",
    "feb_28 = (31 + 28) * 24 + 3  # 28 feb 3h\n",
    "mar_1 = (31 + 28 + 1) * 24 + 3  # 1 mars 3h\n",
    "mar_1_bi = (31 + 29 + 1) * 24 + 3  # 1 mars 3h\n",
    "print_time(feb_28)\n",
    "print(\"1er mars pas bissextile\")\n",
    "print_time(mar_1)\n",
    "print(\"1er mars bissextile\")\n",
    "print_time(mar_1_bi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
